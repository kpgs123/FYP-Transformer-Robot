{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":376},"executionInfo":{"elapsed":482,"status":"error","timestamp":1670870293559,"user":{"displayName":"Geethaka Sandamal","userId":"03856121255503234129"},"user_tz":-330},"id":"11yTpT6IjqMJ","outputId":"13c4bbf4-1177-408a-b243-163f4ba10de9"},"outputs":[{"ename":"AttributeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-d09c5c1bdaa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Warehouse-Layout.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m '''r  esized_img = cv.resize(img, (img.shape[0]*0.1, img.shape[1]*0.1), interpolation = cv.INTER_CUBIC)\n\u001b[1;32m      8\u001b[0m \u001b[0mgray_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresized_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/patches/__init__.py\u001b[0m in \u001b[0;36mcv2_imshow\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \"\"\"\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0;31m# cv2 stores colors as BGR; convert to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'clip'"]}],"source":["import cv2 as cv\n","import numpy as np\n","from google.colab.patches import cv2_imshow\n","\n","img = cv.imread(\"Warehouse-Layout.png\")\n","cv2_imshow(img)\n","'''r  esized_img = cv.resize(img, (img.shape[0]*0.1, img.shape[1]*0.1), interpolation = cv.INTER_CUBIC)\n","gray_img = cv.cvtColor(resized_img, cv.COLOR_BGR2GRAY)\n","cv.imshow(\"gray_img\", gray_img)\n","\n","img2 = cv.Laplacian(gray_img, cv.CV_16SC1)\n","blured_img = cv.GaussianBlur(gray_img, (5, 5), cv.BORDER_DEFAULT)\n","canny_img = cv.Canny(blured_img, 75, 75)\n","img2 = cv.Laplacian(blured_img, cv.CV_16SC1)\n","cv.imshow(\"canny_img\",canny_img)\n","# Resize to fill the whole screen\n","cv.imshow(\"laplacian_img\", img2)\n","cv.imshow(\"blured_img\", blured_img)\n","contours, hierarchy = cv.findContours(canny_img, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n","\n","processed_img = np.zeros(gray_img.shape[:2], dtype = \"uint8\")\n","\n","#cv.drawContours(gray_img, contours, -1, (0, 255, 0), 3)\n","#cv.fillPoly(gray_img, contours, color=(0, 0, 255))\n","cv.drawContours(processed_img, contours, -1, color=(255, 255, 255), thickness=cv.FILLED)\n","cv.imshow(\"processed_img\", processed_img)\n","\n","print(\"Number of contours is %d\" % len(contours))'''"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOgR8siCE0pB2CVnV4eF5dF","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
